### 机器学习新进展第三次课后小实验

201220138 白志欣

[TOC]



#### 一. 作业要求

![image-20231207171056071](C:\Users\hanabi\AppData\Roaming\Typora\typora-user-images\image-20231207171056071.png)

小作业安排如下：

​	Gatys16年的方法、WCT、AdaIN、STROTSS、MAST或Diffusion Image Analogies任选两个复现；

​	可采用原文的代码以及模型或其他开源实现代码；

​	在给的测试图片上跑出实验结果；

​	提交实验报告，给出代码运行截图，简单实验分析报告（开源代码链接）；

#### 二. AdaIN复现

开源代码地址：https://github.com/naoto0804/pytorch-AdaIN?tab=readme-ov-file

![image-20231216235525463](C:\Users\hanabi\AppData\Roaming\Typora\typora-user-images\image-20231216235525463.png)

##### Environment

```
pip install -r requirements.txt
```

- Python 3.8
- cuda 12.2

若找不到requirements.txt中的版本，可把等号去掉，放宽安装限制。

##### 准备

###### 下载预训练的模型

Download [decoder.pth](https://drive.google.com/file/d/1bMfhMMwPeXnYSQI6cDWElSZxOxc6aVyr/view?usp=sharing)/[vgg_normalized.pth](https://drive.google.com/file/d/1EpkBA2K2eYILDSyPTt0fztz59UjAIpZU/view?usp=sharing) and put them under `models/`.

I share the model trained by this code [here](https://drive.google.com/file/d/1YIBRdgGBoVllLhmz_N7PwfeP5V9Vz2Nr/view?usp=sharing)

##### 训练

```bash
CUDA_VISIBLE_DEVICES=0 python train.py --content_dir input/content --style_dir input/style
```

###### 训练过程部分截图

![image-20231217115232203](C:\Users\hanabi\AppData\Roaming\Typora\typora-user-images\image-20231217115232203.png)

![image-20231217115014691](C:\Users\hanabi\AppData\Roaming\Typora\typora-user-images\image-20231217115014691.png)

![image-20231217115039316](C:\Users\hanabi\AppData\Roaming\Typora\typora-user-images\image-20231217115039316.png)

##### 测试

测试阶段直接用了已经训练好的模型。

```bash
CUDA_VISIBLE_DEVICES=1 python test.py --content_dir input/content --style_dir input/style
```

该测试执行后生成了所有对应`style`的`content`图片，结果存在`/output`当中

以一张我自己准备的bitzer的照片（作为content）为例，原图如下：

![bitzer](C:\Users\hanabi\Desktop\头像素材\content\bitzer.jpg)

迁移为其他风格得到的图为：

###### 1.woman_with_hat

style：

![woman_with_hat_matisse](C:\Users\hanabi\pytorch-AdaIN\input\style\woman_with_hat_matisse.jpg)

bitzer_stylized_woman_with_hat_matisse：

![bitzer_stylized_woman_with_hat_matisse](C:\Users\hanabi\pytorch-AdaIN\output\bitzer_stylized_woman_with_hat_matisse.jpg)

###### 2.asheville

style:

![asheville](C:\Users\hanabi\pytorch-AdaIN\input\style\asheville.jpg)

bitzer_stylized_asheville

![bitzer_stylized_asheville](C:\Users\hanabi\pytorch-AdaIN\output\bitzer_stylized_asheville.jpg)

###### 3.trial

style:

![trial](C:\Users\hanabi\pytorch-AdaIN\input\style\trial.jpg)

bitzer_stylized_trial

![bitzer_stylized_trial](C:\Users\hanabi\pytorch-AdaIN\output\bitzer_stylized_trial.jpg)



#### 三.Diffusion Image Analogies复现

![image-20231217115527068](C:\Users\hanabi\AppData\Roaming\Typora\typora-user-images\image-20231217115527068.png)

开源代码地址：https://github.com/subrtadel/DIA

环境配置参照readme文件，可能会报出一些错误，可参照第四部分参考资料修正。

##### 数据集

A

![image-20231217120601667](C:\Users\hanabi\AppData\Roaming\Typora\typora-user-images\image-20231217120601667.png)

A‘

![image-20231217120625087](C:\Users\hanabi\AppData\Roaming\Typora\typora-user-images\image-20231217120625087.png)

B

![image-20231217120646145](C:\Users\hanabi\AppData\Roaming\Typora\typora-user-images\image-20231217120646145.png)



##### 对噪声和条件进行预计算

这一过程较慢

```bash
python precompute_noises_and_conditionings.py     --config ./config/parameter_estimation.yaml     --inversion_subfolder noise     --token_subfolder tokens     --triplet_file triplets.csv     --data_path ./dataset/data/
```

![image-20231217113834418](C:\Users\hanabi\AppData\Roaming\Typora\typora-user-images\image-20231217113834418.png)

![image-20231217113855281](C:\Users\hanabi\AppData\Roaming\Typora\typora-user-images\image-20231217113855281.png)



##### 运行`do_analogies.py`脚本

```bash
python do_analogies.py \
    --config ./config/parameter_estimation.yaml \
    --inversion_subfolder noise \
    --token_subfolder tokens \ 
    --output_subfolder analogies \
    --triplet_file triplets.csv \
    --data_path ./dataset/data/
```



![image-20231217120358286](C:\Users\hanabi\AppData\Roaming\Typora\typora-user-images\image-20231217120358286.png)

不知道为什么，我得到的结果跟官方给出的B’不太一样，有一些生成的图非常诡异：

![image-20231217121322242](C:\Users\hanabi\AppData\Roaming\Typora\typora-user-images\image-20231217121322242.png)



#### 四.参考资料

1.解决报错：

OSError: Can't load tokenizer for 'openai/clip-vit-large-patch14'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'openai/clip-vit-large-patch14' is the correct path to a directory containing all relevant files for a CLIPTokenizer tokenizer.

https://blog.csdn.net/SuperB666/article/details/132826492



2.https://huggingface.co/openai/clip-vit-large-patch14/tree/main